# Generating Counterfactuals Using Variational Autoencoders for Model Interpretability

## Project Overview
### Author: Alexandre Santangelo
### Supervisor: Natasa Tagasovska (Swiss Data Center)
### Date: Spring 2020

## Abstract
This project presents a novel methodology for generating counterfactuals using Conditional Variational Autoencoders (CVAEs), enhancing model interpretability in machine learning. Counterfactuals, essentially altered data samples, aid in interpreting machine learning decision processes. This thesis introduces techniques to modify data samples, such as transforming an image of one class into another, providing insights into classification methods. The approach was successfully tested on two image datasets.

## Acknowledgements
Special thanks to Natasa Tagasovska for her invaluable assistance and guidance throughout this project.

## Disclaimer
Note: This project was completed during my early stages in computer science, and certain coding conventions may not have been fully adhered to.

## Project Details
- **Objective**: Develop a method for generating counterfactuals using CVAEs.
- **Motivation**: Enhance the interpretability of machine learning models.
- **Methodology**: Utilizes the continuous latent space and conditional controlled generation properties of CVAEs. Two methods, ENC-DEC and COND-MIX, were explored for counterfactual generation.
- **Testing and Results**: Applied on MNIST and Colored MNIST datasets, demonstrating the potential of the approach in modifying images for interpretability.
- **Future Scope**: Potentially applicable to other models and datasets, with implications for uncovering biases and improving model understanding.

## Results 
Please read the PDF.

---

_This README.md is a concise summary of the project report and reflects the content and findings of Alexandre Santangelo's bachelor thesis under the supervision of Natasa Tagasovska in Spring 2020._
